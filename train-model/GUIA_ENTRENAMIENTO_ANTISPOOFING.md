# Gu√≠a de Entrenamiento: Modelo de IA para Anti-Spoofing

## üìã Resumen Ejecutivo

Esta gu√≠a describe el proceso para entrenar un modelo de Machine Learning que distingue entre selfies reales y falsos (spoofed/fake), complementando las heur√≠sticas actuales del sistema.

---

## 1. Preparaci√≥n de Datos

### 1.1 Estructura del Dataset

```
Dataset/
‚îú‚îÄ‚îÄ Train/
‚îÇ   ‚îú‚îÄ‚îÄ Real/          # Selfies reales (70% del total)
‚îÇ   ‚îî‚îÄ‚îÄ Fake/          # Selfies falsos/spoofed (70% del total)
‚îú‚îÄ‚îÄ Validation/
‚îÇ   ‚îú‚îÄ‚îÄ Real/          # 15% del total
‚îÇ   ‚îî‚îÄ‚îÄ Fake/          # 15% del total
‚îî‚îÄ‚îÄ Test/
    ‚îú‚îÄ‚îÄ Real/          # 15% del total
    ‚îî‚îÄ‚îÄ Fake/          # 15% del total
```

### 1.2 Requisitos del Dataset

- **M√≠nimo recomendado**: 5,000 im√°genes por clase (Real/Fake)
- **Ideal**: 10,000+ im√°genes por clase
- **Balance**: 50/50 entre Real y Fake
- **Diversidad**: Diferentes condiciones de iluminaci√≥n, √°ngulos, dispositivos, edades, g√©neros
- **Calidad**: Resoluci√≥n m√≠nima 224x224 p√≠xeles
- **Formatos**: JPG, PNG (normalizar a RGB)

### 1.3 T√©cnicas de Data Augmentation

```python
# Transformaciones recomendadas
transforms = [
    RandomHorizontalFlip(p=0.5),
    RandomRotation(degrees=15),
    ColorJitter(brightness=0.2, contrast=0.2),
    RandomAffine(degrees=0, translate=(0.1, 0.1)),
    GaussianBlur(kernel_size=3, p=0.1)
]
```

**No usar**: Flip vertical (cambia la orientaci√≥n facial), rotaciones extremas (>30¬∞)

---

## 2. Arquitectura del Modelo

### 2.1 Opciones Recomendadas

#### Opci√≥n A: EfficientNet-B2 (Recomendada)
- **Ventajas**: Balance entre precisi√≥n y velocidad
- **Par√°metros**: ~9M
- **Tiempo inferencia**: ~50ms (CPU), ~10ms (GPU)
- **Precisi√≥n esperada**: 85-92%

#### Opci√≥n B: MobileNetV3-Large
- **Ventajas**: Muy r√°pido, ideal para producci√≥n
- **Par√°metros**: ~5M
- **Tiempo inferencia**: ~30ms (CPU)
- **Precisi√≥n esperada**: 80-88%

#### Opci√≥n C: ResNet-50
- **Ventajas**: Alta precisi√≥n, bien documentado
- **Par√°metros**: ~25M
- **Tiempo inferencia**: ~100ms (CPU)
- **Precisi√≥n esperada**: 88-94%

### 2.2 Arquitectura Final

```python
import torch
import torch.nn as nn
from torchvision import models

class AntiSpoofingModel(nn.Module):
    def __init__(self, num_classes=2, pretrained=True):
        super().__init__()
        # Backbone: EfficientNet-B2
        self.backbone = models.efficientnet_b2(pretrained=pretrained)
        
        # Reemplazar clasificador final
        num_features = self.backbone.classifier[1].in_features
        self.backbone.classifier = nn.Sequential(
            nn.Dropout(0.3),
            nn.Linear(num_features, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, num_classes)
        )
    
    def forward(self, x):
        return self.backbone(x)
```

---

## 3. Proceso de Entrenamiento

### 3.1 Hiperpar√°metros

```python
config = {
    "batch_size": 32,           # Ajustar seg√∫n GPU RAM
    "learning_rate": 0.001,      # Usar learning rate scheduler
    "epochs": 50,                # Early stopping en epoch 15 sin mejora
    "weight_decay": 0.0001,      # Regularizaci√≥n L2
    "optimizer": "AdamW",        # Alternativa: Adam
    "scheduler": "CosineAnnealingLR",  # Reducir LR gradualmente
    "loss_function": "CrossEntropyLoss",
    "class_weights": [1.0, 1.0]  # Ajustar si hay desbalance
}
```

### 3.2 Script de Entrenamiento (Esquema)

```python
import torch
from torch.utils.data import DataLoader
from torchvision import transforms
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR

# 1. Cargar datos
train_dataset = ImageFolder('Dataset/Train', transform=train_transform)
val_dataset = ImageFolder('Dataset/Validation', transform=val_transform)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# 2. Inicializar modelo
model = AntiSpoofingModel(num_classes=2, pretrained=True)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# 3. Optimizador y scheduler
optimizer = AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)
scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)
criterion = nn.CrossEntropyLoss()

# 4. Loop de entrenamiento
best_val_acc = 0.0
patience = 15
no_improve = 0

for epoch in range(50):
    # Entrenamiento
    model.train()
    train_loss = 0.0
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
    
    # Validaci√≥n
    model.eval()
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()
    
    val_acc = val_correct / val_total
    scheduler.step()
    
    # Early stopping
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), 'best_model.pth')
        no_improve = 0
    else:
        no_improve += 1
        if no_improve >= patience:
            print(f"Early stopping at epoch {epoch+1}")
            break
    
    print(f"Epoch {epoch+1}: Train Loss={train_loss/len(train_loader):.4f}, "
          f"Val Acc={val_acc:.4%}, LR={scheduler.get_last_lr()[0]:.6f}")
```

---

## 4. Evaluaci√≥n y M√©tricas

### 4.1 M√©tricas Clave

```python
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# En conjunto de test
y_true = [...]  # Etiquetas reales
y_pred = [...]  # Predicciones del modelo

accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred, pos_label=1)  # Fake = 1
recall = recall_score(y_true, y_pred, pos_label=1)
f1 = f1_score(y_true, y_pred, pos_label=1)

# Matriz de confusi√≥n
cm = confusion_matrix(y_true, y_pred)
# [[True Negatives, False Positives],
#  [False Negatives, True Positives]]
```

### 4.2 Objetivos de Rendimiento

- **Accuracy**: > 85%
- **Precision (Fake)**: > 80% (evitar falsos positivos)
- **Recall (Fake)**: > 85% (detectar la mayor√≠a de fakes)
- **F1-Score**: > 82%

### 4.3 An√°lisis de Errores

- **Falsos Positivos (Real clasificado como Fake)**: Revisar im√°genes con baja calidad, iluminaci√≥n pobre
- **Falsos Negativos (Fake clasificado como Real)**: Agregar m√°s ejemplos similares al dataset

---

## 5. Optimizaci√≥n y Exportaci√≥n

### 5.1 Quantization (Opcional)

```python
# Reducir tama√±o del modelo para producci√≥n
model_quantized = torch.quantization.quantize_dynamic(
    model, {nn.Linear}, dtype=torch.qint8
)
```

### 5.2 Exportaci√≥n a TorchScript

```python
# Para integraci√≥n en el servicio actual
model.eval()
example_input = torch.rand(1, 3, 224, 224)
traced_model = torch.jit.trace(model, example_input)
traced_model.save('models/antispoofing_model.pt')
```

### 5.3 Integraci√≥n en el Servicio

```python
# En src/ml_classifier.py o nuevo archivo
class AntiSpoofingMLModel:
    def __init__(self, model_path='models/antispoofing_model.pt'):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = torch.jit.load(model_path, map_location=self.device)
        self.model.eval()
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])
    
    def predict(self, image_pil):
        image_tensor = self.transform(image_pil).unsqueeze(0).to(self.device)
        with torch.no_grad():
            outputs = self.model(image_tensor)
            probs = torch.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probs, 1)
        
        return {
            "class": "real" if predicted.item() == 0 else "fake",
            "confidence": confidence.item()
        }
```

---

## 6. Estrategia de Integraci√≥n con Heur√≠sticas

### 6.1 Ensemble (Recomendado)

```python
def detect_with_ensemble(image_pil):
    # Heur√≠sticas (r√°pido, siempre disponible)
    heuristic_result = enhanced_detector.detect(image_pil)
    heuristic_score = heuristic_result['confidence']
    
    # ML Model (m√°s preciso, requiere modelo entrenado)
    ml_result = ml_model.predict(image_pil)
    ml_score = ml_result['confidence']
    
    # Combinaci√≥n ponderada
    final_score = 0.3 * heuristic_score + 0.7 * ml_score
    
    if final_score < 0.5:
        return "real"
    else:
        return "fake"
```

### 6.2 Fallback Strategy

- Si el modelo ML no est√° disponible ‚Üí usar solo heur√≠sticas
- Si heur√≠sticas son muy inciertas (0.4-0.6) ‚Üí usar modelo ML como tie-breaker
- Si ambos coinciden ‚Üí alta confianza

---

## 7. Checklist de Implementaci√≥n

- [ ] Dataset preparado y balanceado (m√≠nimo 5K im√°genes/clase)
- [ ] Data augmentation configurado
- [ ] Modelo seleccionado (EfficientNet-B2 recomendado)
- [ ] Entrenamiento completado (50 epochs o early stopping)
- [ ] M√©tricas de evaluaci√≥n > 85% accuracy
- [ ] Modelo exportado a TorchScript (.pt)
- [ ] Integraci√≥n en `src/antispoofing_enhanced.py`
- [ ] Pruebas en conjunto de test independiente
- [ ] Comparaci√≥n con baseline de heur√≠sticas
- [ ] Documentaci√≥n de rendimiento actualizada

---

## 8. Recursos Adicionales

- **PyTorch Tutorial**: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html
- **EfficientNet Paper**: https://arxiv.org/abs/1905.11946
- **Anti-Spoofing Datasets**: 
  - CASIA-FASD
  - Replay-Attack
  - OULU-NPU
- **Transfer Learning**: Usar modelos pre-entrenados en ImageNet como punto de partida

---

## 9. Notas Finales

- **Tiempo estimado de entrenamiento**: 2-4 horas (GPU) o 8-12 horas (CPU)
- **Hardware recomendado**: GPU con 8GB+ RAM (NVIDIA RTX 3060 o superior)
- **Versi√≥n de PyTorch**: 2.0+ recomendada
- **Monitoreo**: Usar TensorBoard o Weights & Biases para visualizar m√©tricas

---

**√öltima actualizaci√≥n**: 2025-11-27  
**Versi√≥n**: 1.0

